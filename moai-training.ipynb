{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":98462,"databundleVersionId":11751604,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T23:53:05.763067Z","iopub.execute_input":"2025-05-09T23:53:05.763674Z","iopub.status.idle":"2025-05-09T23:53:05.770746Z","shell.execute_reply.started":"2025-05-09T23:53:05.763646Z","shell.execute_reply":"2025-05-09T23:53:05.769985Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/moai-2025-training/test_images.pt\n/kaggle/input/moai-2025-training/train_images.pt\n/kaggle/input/moai-2025-training/train_labels.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport torch\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n# !pip install torchvision\nimport torchvision\n\nimport torch.nn.functional as F\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import TensorDataset\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T23:53:05.772191Z","iopub.execute_input":"2025-05-09T23:53:05.772530Z","iopub.status.idle":"2025-05-09T23:53:05.783624Z","shell.execute_reply.started":"2025-05-09T23:53:05.772501Z","shell.execute_reply":"2025-05-09T23:53:05.783039Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nimport pandas as pd\n\n# --- 小題1：數據讀取與預處理 ---\n# 加载数据\nimages_raw = torch.load('/kaggle/input/moai-2025-training/train_images.pt')  # 假设形状是 [N, H, W]\nlabels_raw = pd.read_csv('/kaggle/input/moai-2025-training/train_labels.csv')\nlabels_raw.info()\n# 检查原始数据形状\nprint(\"Raw images shape:\", images_raw.shape)\nprint(\"Labels shape:\", labels_raw.shape)\n\n# 转换 labels 为 Tensor\nlabels = torch.tensor(labels_raw['label'].values, dtype=torch.long)  # 确保是整数类型\n\n# 添加通道维度并转换为 float32\nimages = images_raw.unsqueeze(1).float()  # 形状变为 [N, 1, H, W]\n\n# 检查处理后的形状\nprint(\"Processed images shape:\", images.shape)\nprint(\"Processed labels shape:\", labels.shape)\n\n# 确保样本数量一致\nassert images.shape[0] == labels.shape[0], \"样本数量不匹配！\"\n\n# 归一化（应在划分数据集后进行，这里仅为演示）\nimages = (images - images.mean()) / images.std()\n\n# 划分训练集和验证集\ndataset = TensorDataset(images, labels)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# --- 小題2：構建CNN模型 ---\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)  # 添加 padding 保持尺寸\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # 假设输入是 28x28，经过两次池化后是 7x7\n        self.fc2 = nn.Linear(128, 10)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 7 * 7)\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T23:53:05.784457Z","iopub.execute_input":"2025-05-09T23:53:05.784714Z","iopub.status.idle":"2025-05-09T23:53:06.179654Z","shell.execute_reply.started":"2025-05-09T23:53:05.784696Z","shell.execute_reply":"2025-05-09T23:53:06.179072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 小題3：訓練模型 ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n\n# 创建 DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T23:58:04.240539Z","iopub.execute_input":"2025-05-09T23:58:04.241237Z","iopub.status.idle":"2025-05-09T23:58:04.252739Z","shell.execute_reply.started":"2025-05-09T23:58:04.241216Z","shell.execute_reply":"2025-05-09T23:58:04.251714Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for epoch in range(55):\n    # 训练阶段\n    model.train()\n    train_loss, train_correct = 0, 0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * inputs.size(0)\n        _, predicted = outputs.max(1)\n        train_correct += predicted.eq(labels).sum().item()\n    \n    # 验证阶段\n    model.eval()\n    val_loss, val_correct = 0, 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            val_correct += predicted.eq(labels).sum().item()\n\n    # 打印结果\n    train_loss /= len(train_dataset)\n    train_acc = train_correct / len(train_dataset)\n    val_loss /= len(val_dataset)\n    val_acc = val_correct / len(val_dataset)\n    \n    print(f\"Epoch {epoch+1}/5\")\n    print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T23:58:07.012420Z","iopub.execute_input":"2025-05-09T23:58:07.013242Z","iopub.status.idle":"2025-05-10T00:00:22.551474Z","shell.execute_reply.started":"2025-05-09T23:58:07.013215Z","shell.execute_reply":"2025-05-10T00:00:22.550740Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\nTrain Loss: 0.1934 | Acc: 0.9450\nVal Loss: 0.0739 | Acc: 0.9780\n\nEpoch 2/5\nTrain Loss: 0.0547 | Acc: 0.9826\nVal Loss: 0.0535 | Acc: 0.9834\n\nEpoch 3/5\nTrain Loss: 0.0378 | Acc: 0.9885\nVal Loss: 0.0506 | Acc: 0.9848\n\nEpoch 4/5\nTrain Loss: 0.0275 | Acc: 0.9911\nVal Loss: 0.0468 | Acc: 0.9852\n\nEpoch 5/5\nTrain Loss: 0.0221 | Acc: 0.9927\nVal Loss: 0.0427 | Acc: 0.9872\n\nEpoch 6/5\nTrain Loss: 0.0151 | Acc: 0.9952\nVal Loss: 0.0498 | Acc: 0.9864\n\nEpoch 7/5\nTrain Loss: 0.0121 | Acc: 0.9962\nVal Loss: 0.0439 | Acc: 0.9898\n\nEpoch 8/5\nTrain Loss: 0.0109 | Acc: 0.9965\nVal Loss: 0.0523 | Acc: 0.9875\n\nEpoch 9/5\nTrain Loss: 0.0083 | Acc: 0.9976\nVal Loss: 0.0522 | Acc: 0.9881\n\nEpoch 10/5\nTrain Loss: 0.0067 | Acc: 0.9978\nVal Loss: 0.0461 | Acc: 0.9892\n\nEpoch 11/5\nTrain Loss: 0.0065 | Acc: 0.9978\nVal Loss: 0.0579 | Acc: 0.9878\n\nEpoch 12/5\nTrain Loss: 0.0070 | Acc: 0.9977\nVal Loss: 0.0552 | Acc: 0.9886\n\nEpoch 13/5\nTrain Loss: 0.0033 | Acc: 0.9990\nVal Loss: 0.0558 | Acc: 0.9883\n\nEpoch 14/5\nTrain Loss: 0.0035 | Acc: 0.9986\nVal Loss: 0.0503 | Acc: 0.9899\n\nEpoch 15/5\nTrain Loss: 0.0041 | Acc: 0.9987\nVal Loss: 0.0564 | Acc: 0.9898\n\nEpoch 16/5\nTrain Loss: 0.0040 | Acc: 0.9987\nVal Loss: 0.0601 | Acc: 0.9888\n\nEpoch 17/5\nTrain Loss: 0.0038 | Acc: 0.9988\nVal Loss: 0.0574 | Acc: 0.9893\n\nEpoch 18/5\nTrain Loss: 0.0027 | Acc: 0.9992\nVal Loss: 0.0557 | Acc: 0.9894\n\nEpoch 19/5\nTrain Loss: 0.0035 | Acc: 0.9988\nVal Loss: 0.0607 | Acc: 0.9889\n\nEpoch 20/5\nTrain Loss: 0.0024 | Acc: 0.9992\nVal Loss: 0.0637 | Acc: 0.9887\n\nEpoch 21/5\nTrain Loss: 0.0034 | Acc: 0.9989\nVal Loss: 0.0647 | Acc: 0.9890\n\nEpoch 22/5\nTrain Loss: 0.0025 | Acc: 0.9992\nVal Loss: 0.0627 | Acc: 0.9900\n\nEpoch 23/5\nTrain Loss: 0.0008 | Acc: 0.9998\nVal Loss: 0.0716 | Acc: 0.9880\n\nEpoch 24/5\nTrain Loss: 0.0009 | Acc: 0.9998\nVal Loss: 0.0745 | Acc: 0.9888\n\nEpoch 25/5\nTrain Loss: 0.0061 | Acc: 0.9980\nVal Loss: 0.0711 | Acc: 0.9886\n\nEpoch 26/5\nTrain Loss: 0.0018 | Acc: 0.9996\nVal Loss: 0.0640 | Acc: 0.9893\n\nEpoch 27/5\nTrain Loss: 0.0008 | Acc: 0.9998\nVal Loss: 0.0701 | Acc: 0.9892\n\nEpoch 28/5\nTrain Loss: 0.0023 | Acc: 0.9992\nVal Loss: 0.0698 | Acc: 0.9888\n\nEpoch 29/5\nTrain Loss: 0.0033 | Acc: 0.9989\nVal Loss: 0.0670 | Acc: 0.9895\n\nEpoch 30/5\nTrain Loss: 0.0004 | Acc: 0.9999\nVal Loss: 0.0620 | Acc: 0.9906\n\nEpoch 31/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0633 | Acc: 0.9906\n\nEpoch 32/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0645 | Acc: 0.9907\n\nEpoch 33/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0658 | Acc: 0.9907\n\nEpoch 34/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0672 | Acc: 0.9907\n\nEpoch 35/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0684 | Acc: 0.9906\n\nEpoch 36/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0698 | Acc: 0.9908\n\nEpoch 37/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0714 | Acc: 0.9908\n\nEpoch 38/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0731 | Acc: 0.9909\n\nEpoch 39/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0750 | Acc: 0.9911\n\nEpoch 40/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0767 | Acc: 0.9910\n\nEpoch 41/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0785 | Acc: 0.9908\n\nEpoch 42/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0805 | Acc: 0.9909\n\nEpoch 43/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0827 | Acc: 0.9908\n\nEpoch 44/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0849 | Acc: 0.9906\n\nEpoch 45/5\nTrain Loss: 0.0094 | Acc: 0.9977\nVal Loss: 0.0660 | Acc: 0.9901\n\nEpoch 46/5\nTrain Loss: 0.0004 | Acc: 0.9999\nVal Loss: 0.0644 | Acc: 0.9909\n\nEpoch 47/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0651 | Acc: 0.9907\n\nEpoch 48/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0662 | Acc: 0.9904\n\nEpoch 49/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0670 | Acc: 0.9906\n\nEpoch 50/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0680 | Acc: 0.9909\n\nEpoch 51/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0691 | Acc: 0.9909\n\nEpoch 52/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0703 | Acc: 0.9913\n\nEpoch 53/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0716 | Acc: 0.9912\n\nEpoch 54/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0732 | Acc: 0.9912\n\nEpoch 55/5\nTrain Loss: 0.0000 | Acc: 1.0000\nVal Loss: 0.0743 | Acc: 0.9913\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# 1. 加载测试集数据\ntest_images_raw = torch.load('/kaggle/input/moai-2025-training/test_images.pt')  # 假设形状是 [N, 28, 28]\ntest_ids = [f\"{i}\" for i in range(len(test_images_raw))]\n # 假设有包含id的CSV文件\n\n# 2. 数据预处理（与训练时相同）\n# 添加通道维度并转换为float32\ntest_images = test_images_raw.unsqueeze(1).float()  # 形状变为 [N, 1, 28, 28]\n\n# 归一化（使用训练时的均值和标准差）\n# 注意：这里应该使用训练时计算的mean和std，这里简化为使用测试集自己的统计量\ntest_images = (test_images - test_images.mean()) / test_images.std()\n\n# 3. 创建测试集DataLoader\ntest_dataset = TensorDataset(test_images)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n# 4. 模型预测\nmodel.eval()  # 设置为评估模式\nall_preds = []\n\nwith torch.no_grad():\n    for inputs in test_loader:\n        inputs = inputs[0].to(device)  # 因为TensorDataset返回的是元组\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n\n# 5. 创建结果DataFrame\nresults = pd.DataFrame({\n    'id': test_ids,\n    'label': all_preds\n})\n\n# 6. 保存为CSV文件\nresults.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(\"预测结果已保存为 submission.csv\")\nprint(\"前5行结果预览:\")\nprint(results.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T00:00:31.150155Z","iopub.execute_input":"2025-05-10T00:00:31.150793Z","iopub.status.idle":"2025-05-10T00:00:31.403139Z","shell.execute_reply.started":"2025-05-10T00:00:31.150768Z","shell.execute_reply":"2025-05-10T00:00:31.402525Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1010977431.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  test_images_raw = torch.load('/kaggle/input/moai-2025-training/test_images.pt')  # 假设形状是 [N, 28, 28]\n","output_type":"stream"},{"name":"stdout","text":"预测结果已保存为 submission.csv\n前5行结果预览:\n  id  label\n0  0      7\n1  1      2\n2  2      1\n3  3      0\n4  4      4\n","output_type":"stream"}],"execution_count":17}]}